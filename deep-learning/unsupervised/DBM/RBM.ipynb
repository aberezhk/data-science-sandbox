{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBM\n",
    "recommender system based on Restricted Boltzmann Machine architecture implemented with python.\n",
    "Model predicts binary value wheter user will like (1) or not like (0) a movie. To generate test data data_preprocessing notebook shall be exected first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_original = np.loadtxt('training_set_flat.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(training_data_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_original = np.loadtxt('test_set_flat.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_data_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(data_set):\n",
    "    data_set[data_set == 2] = 0\n",
    "    data_set[data_set >= 3] = 1\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = convert_to_binary(training_data_original)\n",
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -1., -1., ..., -1., -1., -1.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = convert_to_binary(test_data_original)\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBM():\n",
    "    def __init__(self, number_visible_nodes, number_hidden_nodes):\n",
    "        # Weights W (visible*hidden) => (rows*columns)\n",
    "        self.W = np.random.randn(number_visible_nodes, number_hidden_nodes)\n",
    "        # print('W shape: '+ str(np.shape(self.W)))\n",
    "        # print('W [0]: '+ str(self.W[0]))\n",
    "        # hidden_bias (1*hidden )\n",
    "        self.hidden_bias = np.random.randn(1, number_hidden_nodes)\n",
    "        # print('hidden_bias shape: '+ str(np.shape(self.hidden_bias)))\n",
    "        # print('hidden_bias [0]: '+ str(self.hidden_bias[0]))\n",
    "        # visible_bias (1*visible)\n",
    "        self.visible_bias = np.random.randn(1, number_visible_nodes)\n",
    "        # print('visible_bias shape: '+ str(np.shape(self.visible_bias)))\n",
    "        # print('visible_bias [0]: '+ str(self.visible_bias[0]))\n",
    "        \n",
    "    def sample_hidden_nodes(self, visible_nodes):\n",
    "        # visible_nodes (batch_size*v_nodes), W (v_nodes*h_nodes), hidden_nodes (batch_size*h_nodes)\n",
    "        hidden_nodes = np.dot(visible_nodes, self.W) \n",
    "        # print('hidden_nodes shape: '+ str(np.shape(hidden_nodes)))\n",
    "        # weights plus biases: hidden_nodes (batch_size, h_nodes) + hidden_bias (1, h_nodes)\n",
    "        activation_hidden = hidden_nodes + self.hidden_bias # add biases to hidden nodes values\n",
    "        # print('activation_hidden shape: '+ str(np.shape(activation_hidden)))\n",
    "        \n",
    "        # apply sigmoid function to get hidden nodes values between 0 and 1, p_hidden_given_visible (batch_size*h_nodes)\n",
    "        p_hidden_given_visible = 1/(1 + np.exp(-activation_hidden))\n",
    "        # print('p_hidden_given_visible shape: '+ str(np.shape(p_hidden_given_visible)))\n",
    "        \n",
    "        rows = p_hidden_given_visible.shape[0]\n",
    "        columns = p_hidden_given_visible.shape[1]\n",
    "        # convert probabilities to 0/1 with respoct to bernouli distribution\n",
    "        hidden_given_visible = np.random.binomial(1, p_hidden_given_visible, size=[rows,columns])\n",
    "        # print('hidden_given_visible shape: '+ str(np.shape(hidden_given_visible)))\n",
    "        # print('hidden_given_visible[0]: '+ str(hidden_given_visible[0]))\n",
    "        \n",
    "        return p_hidden_given_visible, hidden_given_visible\n",
    "        \n",
    "    def sample_visible_nodes(self, hidden_nodes):\n",
    "        # hidden_nodes (batch_size*h_nodes), np.transpose(W) (h_nodes*v_nodes), visible_nodes (batch_size*v_nodes)\n",
    "        visible_nodes = np.dot(hidden_nodes, np.transpose(self.W))\n",
    "        \n",
    "        activation_visible = visible_nodes + self.visible_bias\n",
    "        \n",
    "        p_visible_given_hidden = 1/(1 + np.exp(-activation_visible))\n",
    "        \n",
    "        rows = p_visible_given_hidden.shape[0]\n",
    "        columns = p_visible_given_hidden.shape[1]\n",
    "        visible_given_hidden = np.random.binomial(1, p_visible_given_hidden, size=[rows,columns])\n",
    "        # print('visible_given_hidden shape: '+ str(np.shape(visible_given_hidden)))\n",
    "        # print('visible_given_hidden[0]: '+ str(visible_given_hidden[0]))\n",
    "        \n",
    "        return p_visible_given_hidden, visible_given_hidden\n",
    "    \n",
    "    def train(self, original_v, current_v, p_original_h, p_current_h, learning_rate):\n",
    "        \n",
    "        # np.transpose(original_v) (v_nodes*batch_size), p_original_v (batch_size*h_nodes), diff_original (v_nodes*h_nodes)\n",
    "        dot_original = np.dot(np.transpose(original_v), p_original_h)\n",
    "        # print('dot_original shape: '+ str(np.shape(dot_original)))\n",
    "        # diff_current (v_nodes*h_nodes)\n",
    "        dot_current = np.dot(np.transpose(current_v), p_current_h)\n",
    "        # print('dot_current shape: '+ str(np.shape(dot_current)))\n",
    "        \n",
    "        # print('initial W shape: '+ str(np.shape(self.W)))\n",
    "        self.W +=  learning_rate * (dot_original - dot_current)\n",
    "        # print('updated W shape: '+ str(np.shape(self.W)))\n",
    "        \n",
    "        self.visible_bias += np.sum(original_v - current_v)\n",
    "        # print('updated visible_bias shape: '+ str(np.shape(self.visible_bias)))\n",
    "        self.hidden_bias += np.sum(p_original_h - p_current_h)\n",
    "        # print('updated hidden_bias shape: '+ str(np.shape(self.hidden_bias)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_visible_nodes = len(training_data[0])\n",
    "number_hidden_nodes = 100\n",
    "batch_size = 250\n",
    "learning_rate= 0.1\n",
    "nb_epoch = 5\n",
    "rbm = RBM(number_visible_nodes, number_hidden_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.18295419937161095\n",
      "epoch: 2 loss: 0.2022736752272624\n",
      "epoch: 3 loss: 0.16836269168209206\n",
      "epoch: 4 loss: 0.20274841976666752\n",
      "epoch: 5 loss: 0.20108287342494016\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(nb_epoch):\n",
    "    train_loss = 0\n",
    "    s = 0\n",
    "    for n_user in range(0, len(training_data), batch_size):\n",
    "        # visible nodes are the actual ratings\n",
    "        current_v = training_data[n_user:n_user+batch_size] # this one will be updated => reconstructed nodes\n",
    "        original_v = training_data[n_user:n_user+batch_size] # this is used to calculate error of reconstructed nodes\n",
    "        # hidden nodes after 1 sampling (before learning), with values that are between 0 and 1 (probability of being activated)\n",
    "        p_original_h,_ = rbm.sample_hidden_nodes(original_v)\n",
    "        \n",
    "        # Markov chain Monte Carlo (MCMC) algorithm\n",
    "        for k in range(5):\n",
    "            # run forward - sample hidden nodes\n",
    "            _,current_h = rbm.sample_hidden_nodes(current_v)\n",
    "            # run backward - reconstruct visible nodes\n",
    "            _,current_v = rbm.sample_visible_nodes(current_h)\n",
    "            \n",
    "            # revert to -1 values that were not rated originally\n",
    "            current_v[original_v<0] = original_v[original_v<0]\n",
    "            # print('current_v[0]: '+ str(current_v[0]))\n",
    "            # print('original_v[0]: '+ str(original_v[0]))\n",
    "            \n",
    "        # run forward, get predicted probabilities of hidden node to be activated (between 0 and 1)\n",
    "        p_current_h,_ = rbm.sample_hidden_nodes(current_v)\n",
    "        \n",
    "        # train the model - reduce difference between generated and original visible nodes\n",
    "        rbm.train(original_v, current_v, p_original_h, p_current_h, learning_rate)\n",
    "        # calculate diff between original and recretaed node values for current batch\n",
    "        diff_original_current = np.mean(np.absolute(original_v[original_v>=0] - current_v[original_v>=0]))\n",
    "        # update train loss per epoch\n",
    "        train_loss += diff_original_current\n",
    "        s += 1\n",
    "        #print('epoch: '+str(epoch +1)+' batch: ' + str(s) +' current loss: '+str(diff_original_current))\n",
    "    #print('current_v[0]: '+ str(current_v[0]))\n",
    "    #print('original_v[0]: '+ str(original_v[0]))\n",
    "    print('epoch: '+str(epoch +1)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.09149395531496649\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "for user in range(len(training_data)):\n",
    "    v_nodes_train = training_data[user:user+1]\n",
    "    v_nodes_test = test_data[user:user+1]\n",
    "    # create hidden nodes based on visible nodes for given user from training set\n",
    "    _,hidden_nodes = rbm.sample_hidden_nodes(v_nodes_train)\n",
    "    # reconstruct visible nodes based on calculated hidden nodes\n",
    "    _,reconstructed_visible_nodes = rbm.sample_visible_nodes(hidden_nodes)\n",
    "    # compare if model guessed correctly if user will like the movies based on train set data\n",
    "    # (some movies rated by same user are in train set, other are in test set)\n",
    "    # calculate loss for each user and devide by number of users\n",
    "    test_loss += np.mean(np.absolute(v_nodes_test[v_nodes_test>=0] - reconstructed_visible_nodes[v_nodes_test>=0]))\n",
    "    s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
